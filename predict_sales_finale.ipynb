{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from itertools import product\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def downcast_dtypes(df):\n",
    "    # Select columns to downcast\n",
    "    float_cols = [c for c in df if df[c].dtype == \"float64\"]\n",
    "    int_cols =   [c for c in df if df[c].dtype == \"int64\"]\n",
    "\n",
    "    # Downcast\n",
    "    df[float_cols] = df[float_cols].astype(np.float32)\n",
    "    df[int_cols]   = df[int_cols].astype(np.int32)\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_folder = \"/home/wenceslai/Documents/predict_sales_kaggle\"\n",
    "\n",
    "train = pd.read_csv(os.path.join(data_folder, 'sales_train.csv'))\n",
    "item_cats = pd.read_csv(os.path.join(data_folder, 'items.csv'))\n",
    "df_sub = pd.read_csv(os.path.join(data_folder, 'sample_submission.csv'))\n",
    "test = pd.read_csv(os.path.join(data_folder, 'test.csv'))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "#fixing some abnormalities in the data\n",
    "\n",
    "train = train[train.item_price<100000]\n",
    "train = train[train.item_cnt_day<1001]\n",
    "\n",
    "# Якутск Орджоникидзе, 56\n",
    "train.loc[train.shop_id == 0, 'shop_id'] = 57\n",
    "test.loc[test.shop_id == 0, 'shop_id'] = 57\n",
    "# Якутск ТЦ \"Центральный\"\n",
    "train.loc[train.shop_id == 1, 'shop_id'] = 58\n",
    "test.loc[test.shop_id == 1, 'shop_id'] = 58\n",
    "# Жуковский ул. Чкалова 39м²\n",
    "train.loc[train.shop_id == 10, 'shop_id'] = 11\n",
    "test.loc[test.shop_id == 10, 'shop_id'] = 11\n",
    "\n",
    "median = train[(train.shop_id==32)&(train.item_id==2973)&(train.date_block_num==4)&(train.item_price>0)].item_price.median()\n",
    "train.loc[train.item_price<0, 'item_price'] = median\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "creating every possible pair of shop_id and item_id even if there are no sales of it in current month\n",
    "we are doing this to mimic the distribution in the test data\n",
    "\"\"\"\n",
    "\n",
    "matrix = []\n",
    "cols = ['date_block_num','shop_id','item_id']\n",
    "\n",
    "for i in range(34):\n",
    "    sales = train[train.date_block_num==i]\n",
    "    matrix.append(np.array(list(product([i], sales.shop_id.unique(), sales.item_id.unique())), dtype='int16'))\n",
    "\n",
    "matrix = pd.DataFrame(np.vstack(matrix), columns=cols)\n",
    "matrix['date_block_num'] = matrix['date_block_num'].astype(np.int8)\n",
    "matrix.sort_values(cols,inplace=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "#test vals\n",
    "test['date_block_num'] = 34\n",
    "test = test.drop('ID', axis=1)\n",
    "test = test[['date_block_num', 'shop_id', 'item_id']]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "#aggregating item_cnt_day for whole month as in test set\n",
    "group = train.groupby(['date_block_num','shop_id','item_id']).agg({'item_cnt_day': ['sum']})\n",
    "group.columns = ['item_cnt_month']\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=cols, how='left')\n",
    "matrix['item_cnt_month'] = (matrix['item_cnt_month']\n",
    "                                .fillna(0)\n",
    "                                .clip(0,20)\n",
    "                                .astype(np.float16))\n",
    "\n",
    "all_data = pd.concat([matrix, test])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_sales = all_data.groupby('date_block_num')['month_sum'].sum()\n",
    "plt.plot(range(34), M_sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lag features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def lag_features(df, lags, col):\n",
    "    subset = df[['date_block_num', 'shop_id', 'item_id', col]]\n",
    "    for lag in lags:\n",
    "        shifted = subset.copy()\n",
    "        shifted.cols = [['date_block_num', 'shop_id', 'item_id', col+\"_lag_\"+str(lag)]]\n",
    "        shifted.rename(columns={col : col+\"_lag_\"+str(lag)}, inplace=True)\n",
    "        shifted['date_block_num'] += lag\n",
    "        df = df.merge(shifted, on=['date_block_num', 'shop_id', 'item_id'], how='left').fillna(0)\n",
    "    del shifted\n",
    "\n",
    "    return df\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   date_block_num  shop_id  item_id  item_cnt_month  item_cnt_month_lag_1  \\\n0               0        2       19             0.0                   0.0   \n1               0        2       27             1.0                   0.0   \n2               0        2       28             0.0                   0.0   \n3               0        2       29             0.0                   0.0   \n4               0        2       32             0.0                   0.0   \n\n   item_cnt_month_lag_2  item_cnt_month_lag_3  item_cnt_month_lag_5  \\\n0                   0.0                   0.0                   0.0   \n1                   0.0                   0.0                   0.0   \n2                   0.0                   0.0                   0.0   \n3                   0.0                   0.0                   0.0   \n4                   0.0                   0.0                   0.0   \n\n   item_cnt_month_lag_12  \n0                    0.0  \n1                    0.0  \n2                    0.0  \n3                    0.0  \n4                    0.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date_block_num</th>\n      <th>shop_id</th>\n      <th>item_id</th>\n      <th>item_cnt_month</th>\n      <th>item_cnt_month_lag_1</th>\n      <th>item_cnt_month_lag_2</th>\n      <th>item_cnt_month_lag_3</th>\n      <th>item_cnt_month_lag_5</th>\n      <th>item_cnt_month_lag_12</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2</td>\n      <td>19</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>2</td>\n      <td>27</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>2</td>\n      <td>28</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>2</td>\n      <td>29</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>2</td>\n      <td>32</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "\n",
    "all_data = downcast_dtypes(all_data)\n",
    "\n",
    "all_data = lag_features(all_data, [1, 2, 3, 5, 12], 'item_cnt_month')\n",
    "\n",
    "all_data.head()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "#adding categories\n",
    "all_data = all_data.merge(item_cats.drop('item_name', axis=1), on='item_id', how='left')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% [markdown]\n"
    }
   },
   "source": [
    "# Mean encoding\n",
    "\n",
    "to avoid overfitting we encode features based on one month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "temp = all_data.groupby(['date_block_num']).agg({'item_cnt_month' : ['mean']})\n",
    "temp.columns = ['date_block_num_meanenc']\n",
    "temp.reset_index(inplace=True)\n",
    "\n",
    "all_data = all_data.merge(temp, on=['date_block_num'], how='left')\n",
    "all_data['date_block_num_meanenc'] = all_data['date_block_num_meanenc'].astype('float16')\n",
    "\n",
    "all_data = lag_features(all_data, [1], 'date_block_num_meanenc')\n",
    "all_data = all_data.drop('date_block_num_meanenc', axis=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "temp = all_data.groupby(['date_block_num', 'item_id']).agg({'item_cnt_month' : ['mean']})\n",
    "temp.columns = ['item_id_meanenc']\n",
    "temp.reset_index(inplace=True)\n",
    "\n",
    "all_data = all_data.merge(temp, on=['date_block_num', 'item_id'], how='left')\n",
    "all_data['item_id_meanenc'] = all_data['item_id_meanenc'].astype('float16')\n",
    "\n",
    "all_data = lag_features(all_data, [1], 'item_id_meanenc')\n",
    "all_data = all_data.drop('item_id_meanenc', axis=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "temp = all_data.groupby(['date_block_num', 'shop_id']).agg({'item_cnt_month' : ['mean']})\n",
    "temp.columns = ['shop_id_meanenc']\n",
    "temp.reset_index(inplace=True)\n",
    "\n",
    "all_data = all_data.merge(temp, on=['date_block_num', 'shop_id'], how='left')\n",
    "all_data['shop_id_meanenc'] = all_data['shop_id_meanenc'].astype('float16')\n",
    "\n",
    "all_data = lag_features(all_data, [1, 2, 3, 5, 12], 'shop_id_meanenc')\n",
    "all_data = all_data.drop('shop_id_meanenc', axis=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "temp = all_data.groupby(['date_block_num', 'item_category_id']).agg({'item_cnt_month' : ['mean']})\n",
    "temp.columns = ['item_category_id_meanenc']\n",
    "temp.reset_index(inplace=True)\n",
    "\n",
    "all_data = all_data.merge(temp, on=['date_block_num', 'item_category_id'], how='left')\n",
    "all_data['item_category_id_meanenc'] = all_data['item_category_id_meanenc'].astype('float16')\n",
    "\n",
    "all_data = lag_features(all_data, [1], 'item_category_id_meanenc')\n",
    "all_data = all_data.drop('item_category_id_meanenc', axis=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "date_block_num                    0\nshop_id                           0\nitem_id                           0\nitem_cnt_month                    0\nitem_cnt_month_lag_1              0\nitem_cnt_month_lag_2              0\nitem_cnt_month_lag_3              0\nitem_cnt_month_lag_5              0\nitem_cnt_month_lag_12             0\nitem_category_id                  0\ndate_block_num_meanenc_lag_1      0\nitem_id_meanenc_lag_1             0\nshop_id_meanenc_lag_1             0\nshop_id_meanenc_lag_2             0\nshop_id_meanenc_lag_3             0\nshop_id_meanenc_lag_5             0\nshop_id_meanenc_lag_12            0\nitem_category_id_meanenc_lag_1    0\navg_price_total                   0\ndtype: int64"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "all_data.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% [markdown]\n"
    }
   },
   "source": [
    "# Price and special features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "#adding prices\n",
    "prices = train.groupby('item_id').agg({'item_price' : ['mean']})\n",
    "prices.columns = ['avg_price_total']\n",
    "prices = prices.reset_index()\n",
    "\n",
    "all_data = all_data.merge(prices, on='item_id', how='left')\n",
    "all_data = all_data.fillna(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "this left 20% nan values so i left it out of final dataframe\n",
    "\n",
    "prices = train.groupby(['date_block_num', 'item_id']).agg({'item_price' : ['mean']})\n",
    "prices.columns = ['avg_price_month']\n",
    "prices = prices.reset_index()\n",
    "prices.head()\n",
    "\n",
    "all_data = all_data.merge(prices, on=['date_block_num', 'item_id'], how='left')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "#adding seasonality in forms of month\n",
    "all_data['month'] = all_data['date_block_num'] % 12"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% [markdown]\n"
    }
   },
   "source": [
    "# Training and Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_tresh = 34 #34 if we do not want to validate\n",
    "\n",
    "all_data = all_data[all_data['date_block_num'] > 11] #because maximum lag used 12 we can delete\n",
    "\n",
    "X_train = all_data[all_data['date_block_num'] < val_tresh].drop('item_cnt_month', axis=1).values\n",
    "y_train = all_data.loc[all_data['date_block_num'] < val_tresh]['item_cnt_month'].values\n",
    "\n",
    "\n",
    "X_val = all_data[all_data['date_block_num'] == val_tresh].drop('item_cnt_month', axis=1).values\n",
    "y_val = all_data[all_data['date_block_num'] == val_tresh]['item_cnt_month'].values\n",
    "\n",
    "X_test = all_data[all_data['date_block_num'] == 34].drop('item_cnt_month', axis=1).values\n",
    "\n",
    "y_train = y_train.clip(0, 20)\n",
    "y_val = y_val.clip(0, 20)\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[20:47:38] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n[20:47:38] WARNING: src/learner.cc:686: Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\n[0]\tvalidation_0-rmse:1.12786\tvalidation_1-rmse:1.12269\nMultiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n\nWill train until validation_1-rmse hasn't improved in 9 rounds.\n[1]\tvalidation_0-rmse:1.09062\tvalidation_1-rmse:1.09086\n[2]\tvalidation_0-rmse:1.06099\tvalidation_1-rmse:1.06533\n[3]\tvalidation_0-rmse:1.02533\tvalidation_1-rmse:1.04373\n[4]\tvalidation_0-rmse:0.999671\tvalidation_1-rmse:1.02597\n[5]\tvalidation_0-rmse:0.978927\tvalidation_1-rmse:1.01196\n[6]\tvalidation_0-rmse:0.963874\tvalidation_1-rmse:0.999842\n[7]\tvalidation_0-rmse:0.946149\tvalidation_1-rmse:0.991435\n[8]\tvalidation_0-rmse:0.932768\tvalidation_1-rmse:0.982304\n[9]\tvalidation_0-rmse:0.922496\tvalidation_1-rmse:0.975509\n[10]\tvalidation_0-rmse:0.913073\tvalidation_1-rmse:0.969145\n[11]\tvalidation_0-rmse:0.903857\tvalidation_1-rmse:0.964049\n[12]\tvalidation_0-rmse:0.897408\tvalidation_1-rmse:0.96053\n[13]\tvalidation_0-rmse:0.890994\tvalidation_1-rmse:0.95532\n[14]\tvalidation_0-rmse:0.885384\tvalidation_1-rmse:0.950897\n[15]\tvalidation_0-rmse:0.88066\tvalidation_1-rmse:0.94871\n[16]\tvalidation_0-rmse:0.876704\tvalidation_1-rmse:0.947167\n[17]\tvalidation_0-rmse:0.873387\tvalidation_1-rmse:0.945449\n[18]\tvalidation_0-rmse:0.869167\tvalidation_1-rmse:0.941947\n[19]\tvalidation_0-rmse:0.866728\tvalidation_1-rmse:0.940128\n[20]\tvalidation_0-rmse:0.86352\tvalidation_1-rmse:0.937466\n[21]\tvalidation_0-rmse:0.861065\tvalidation_1-rmse:0.936526\n[22]\tvalidation_0-rmse:0.859354\tvalidation_1-rmse:0.936169\n[23]\tvalidation_0-rmse:0.857767\tvalidation_1-rmse:0.935554\n[24]\tvalidation_0-rmse:0.856308\tvalidation_1-rmse:0.935524\n[25]\tvalidation_0-rmse:0.85512\tvalidation_1-rmse:0.935573\n[26]\tvalidation_0-rmse:0.8539\tvalidation_1-rmse:0.935207\n[27]\tvalidation_0-rmse:0.852368\tvalidation_1-rmse:0.935397\n[28]\tvalidation_0-rmse:0.851137\tvalidation_1-rmse:0.935508\n[29]\tvalidation_0-rmse:0.850264\tvalidation_1-rmse:0.935175\n[30]\tvalidation_0-rmse:0.849142\tvalidation_1-rmse:0.935452\n[31]\tvalidation_0-rmse:0.848213\tvalidation_1-rmse:0.93521\n[32]\tvalidation_0-rmse:0.847338\tvalidation_1-rmse:0.934652\n[33]\tvalidation_0-rmse:0.846319\tvalidation_1-rmse:0.934716\n[34]\tvalidation_0-rmse:0.845816\tvalidation_1-rmse:0.934473\n[35]\tvalidation_0-rmse:0.844469\tvalidation_1-rmse:0.934275\n[36]\tvalidation_0-rmse:0.84368\tvalidation_1-rmse:0.934047\n[37]\tvalidation_0-rmse:0.843133\tvalidation_1-rmse:0.934166\n[38]\tvalidation_0-rmse:0.842436\tvalidation_1-rmse:0.934305\n[39]\tvalidation_0-rmse:0.841697\tvalidation_1-rmse:0.934183\n[40]\tvalidation_0-rmse:0.84121\tvalidation_1-rmse:0.933947\n[41]\tvalidation_0-rmse:0.840513\tvalidation_1-rmse:0.934326\n[42]\tvalidation_0-rmse:0.839803\tvalidation_1-rmse:0.933908\n[43]\tvalidation_0-rmse:0.839226\tvalidation_1-rmse:0.934421\n[44]\tvalidation_0-rmse:0.838892\tvalidation_1-rmse:0.934532\n[45]\tvalidation_0-rmse:0.837623\tvalidation_1-rmse:0.93458\n[46]\tvalidation_0-rmse:0.837065\tvalidation_1-rmse:0.934073\n[47]\tvalidation_0-rmse:0.836193\tvalidation_1-rmse:0.934241\n[48]\tvalidation_0-rmse:0.835613\tvalidation_1-rmse:0.934444\n[49]\tvalidation_0-rmse:0.835092\tvalidation_1-rmse:0.935086\n[50]\tvalidation_0-rmse:0.834622\tvalidation_1-rmse:0.93545\n[51]\tvalidation_0-rmse:0.834155\tvalidation_1-rmse:0.935269\nStopping. Best iteration:\n[42]\tvalidation_0-rmse:0.839803\tvalidation_1-rmse:0.933908\n\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "XGBRegressor(colsample_bytree=0.8, eta=0.3, max_depth=8, min_child_weight=300,\n             n_estimators=1000, seed=42, subsample=0.8)"
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "#XGBoost \n",
    "from xgboost import XGBRegressor \n",
    "\n",
    "model_xgb = XGBRegressor(\n",
    "    max_depth=8,\n",
    "    n_estimators=1000,\n",
    "    min_child_weight=300,\n",
    "    colsample_bytree=0.8,\n",
    "    subsample=0.8,\n",
    "    eta=0.3,\n",
    "    seed=42)\n",
    "\n",
    "model_xgb.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    n_estimators=42, \n",
    "    #eval_metric=\"rmse\",\n",
    "    #eval_set=[(X_train, y_train), (X_val, y_val)]\n",
    "    #early_stopping_rounds = 9\n",
    "    verbose=True\n",
    "    )\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\nWARNING:tensorflow:From /home/wenceslai/anaconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n\nWARNING:tensorflow:From /home/wenceslai/anaconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n\nWARNING:tensorflow:From /home/wenceslai/anaconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n\nWARNING:tensorflow:From /home/wenceslai/anaconda3/envs/tf/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n\n"
    }
   ],
   "source": [
    "#Neural Network\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "model_nn = models.Sequential()\n",
    "model_nn.add(layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model_nn.add(layers.Dense(32, activation='relu',))\n",
    "model_nn.add(layers.Dense(1))\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "\n",
    "model_nn.compile(\n",
    "    optimizer='rmsprop',\n",
    "    loss=root_mean_squared_error,\n",
    "    metrics=[root_mean_squared_error]\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 6186922 samples, validate on 238172 samples\nEpoch 1/3\n6186922/6186922 [==============================] - 250s 40us/step - loss: 0.8153 - root_mean_squared_error: 0.8153 - val_loss: 0.6713 - val_root_mean_squared_error: 0.6713\nEpoch 2/3\n6186922/6186922 [==============================] - 239s 39us/step - loss: 0.8108 - root_mean_squared_error: 0.8108 - val_loss: 0.6761 - val_root_mean_squared_error: 0.6761\nEpoch 3/3\n6186922/6186922 [==============================] - 247s 40us/step - loss: 0.8096 - root_mean_squared_error: 0.8096 - val_loss: 0.6725 - val_root_mean_squared_error: 0.6725\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<keras.callbacks.History at 0x7ff46c2dfb10>"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "model_nn.fit(\n",
    "    X_train, y_train,\n",
    "    #validation_data=(X_val, y_val),\n",
    "    epochs=1,\n",
    "    batch_size=64,\n",
    "    verbose=True\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model_rf = RandomForestRegressor(n_jobs=-1, verbose=1, n_estimators=50, max_depth=25, random_state=18)\n",
    "model_rf.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_preds = model_rf.predict(X_val).clip(0, 20)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_val, y_preds))\n",
    "print(\"validation RMSE:\", rmse)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(214200,)"
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "preds_nn.ravel().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "done\n"
    }
   ],
   "source": [
    "preds_xgb = model_xgb.predict(X_test).clip(0, 20) #ensebling\n",
    "preds_nn = model_nn.predict(X_test).clip(0, 20)\n",
    "\n",
    "preds = (model_xgb.predict(X_test).clip(0, 20) + model_nn.predict(X_test).clip(0, 20).squeeze()) / 2\n",
    "\n",
    "df_sub['item_cnt_month'] = preds #round?\n",
    "df_sub.to_csv(os.path.join(data_folder, 'sub_out_nn'), index=False)\n",
    "print(\"done\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}